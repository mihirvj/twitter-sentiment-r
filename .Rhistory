mydata = scan()
mydata = scan()
temps = scan()
mydata = c(NA)
data.entry(mydata)
data.entry(mydata)
install.packages("streamMOA")
library("streamMOA")
stream <- DSD_Gaussians(k=3, d=2, noise=0.05)
plot(stream)
micro.clusters <-DSC_CluStream(m=50)
update(micro.clusters, stream, 500)
micro.clusters
plot(micro.clusters, stream)
macro.clusters <-DSC_Kmeans(k=3)
recluster(macro.clusters, micro.clusters)
macro.clusters
plot(macro.clusters, stream, type="both")
setwd("Documents/Advanced_Algorithms/Assignments/P3/twitter-sentiment-r/")
source("data_retrieval.R")
source("preprocessing.R")
source("feature_construction.R")
source("training.R")
tweets = retrieve.tweets(n=1000)
tweets$text <- sapply(tweets$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
vc_tweets = Corpus(VectorSource(as.character(tweets$text)))
vc_tweets = process.tweets(vc_tweets)
# create Document-Term Matrix
tweets.tdm <- DocumentTermMatrix(vc_tweets, control=list(minWordLength=1))
# separate into training and test data
index <- sample(1:dim(tweets.tdm)[1])
tweets.tdm.training <- tweets.tdm[index[1:floor(dim(tweets.tdm)[1]/2)],]
tweets.tdm.test <- tweets.tdm[index[((ceiling(dim(tweets.tdm)[1]/2)) + 1):dim(tweets.tdm)[1]],]
# extract features from training data
tweets.tdm.df <- extract.features(tweets.tdm.training)
# assign 'Class' to tweets
tweets.tdm.df["Class"] <- "love"
tweets.tdm.df[tweets.tdm.df$hate > 0, "Class"] <- "hate"
# removes 'love' and 'hate' from the feature set
tweets.tdm.df <- tweets.tdm.df[setdiff(colnames(tweets.tdm.df), c("love", "hate"))]
# train model
tweetModel <- trainModel(tweets.tdm.df, training = T)
predictions <- predict(tweetModel, newdata = tweets.tdm.df, type = "response")
summary(predictions)
table(predictions,tweets.tdm.df[,ncol(tweets.tdm.df)])
test.matrix <- as.matrix(tweets.tdm.test)
tweets.tdm.test <- as.data.frame(test.matrix)
# add 'Class' to test data
tweets.tdm.test["Class"] <- "love"
tweets.tdm.test[tweets.tdm.test$hate > 0, "Class"] <- "hate"
tweets.tdm.test <- tweets.tdm.test[setdiff(colnames(tweets.tdm.test), c("love", "hate"))]
# predict using our model for test data
#prediction <- predict(tweetModel, newdata = tweets.tdm.test, type = "response")
#newModel <- trainModel(tweets.tdm.test, training = F, trainedModel = tweetModel)
tp <- 0
tn <- 0
fp <- 0
fn <- 0
for(i in seq(1, dim(tweets.tdm.test)[1], 10)) {
dataset <- tweets.tdm.test[seq(i:i+9),]
prediction <- predict(tweetModel, newdata = dataset, type = "response")
tweetModel <- trainModel(dataset, training = F, trainedModel = tweetModel)
cm <- table(prediction,dataset[,ncol(dataset)])
if(!is.na(cm['love',])) {
tp <- tp + cm['love', 'love']
fp <- fp + cm['love', 'hate']
}
if(!is.na(cm['hate',])) {
tn <- tn + cm['hate', 'hate']
fn <- fn + cm['hate', 'love']
}
}
cm
cm['hate']
cm['hate',]
for(i in seq(1, dim(tweets.tdm.test)[1], 10)) {
dataset <- tweets.tdm.test[seq(i:i+9),]
prediction <- predict(tweetModel, newdata = dataset, type = "response")
tweetModel <- trainModel(dataset, training = F, trainedModel = tweetModel)
cm <- table(prediction,dataset[,ncol(dataset)])
if(!is.na(cm['love'])) {
tp <- tp + cm['love', 'love']
fp <- fp + cm['love', 'hate']
}
if(!is.na(cm['hate'])) {
tn <- tn + cm['hate', 'hate']
fn <- fn + cm['hate', 'love']
}
}
tp <- 0
tn <- 0
fp <- 0
fn <- 0
for(i in seq(1, dim(tweets.tdm.test)[1], 10)) {
dataset <- tweets.tdm.test[seq(i:i+9),]
prediction <- predict(tweetModel, newdata = dataset, type = "response")
tweetModel <- trainModel(dataset, training = F, trainedModel = tweetModel)
cm <- table(prediction,dataset[,ncol(dataset)])
print(paste('running iteration ', i))
if(!is.na(cm['love'])) {
tp <- tp + cm['love', 'love']
fp <- fp + cm['love', 'hate']
}
if(!is.na(cm['hate'])) {
tn <- tn + cm['hate', 'hate']
fn <- fn + cm['hate', 'love']
}
}
(tp+tn) / (tp+tn+fp+fn)
tp+tn
tp+tn+fp+fn
cm
cm['love']
cm['love',]
cm['hate',]
cm[cm$love]
(402+47)/(402+47+10+41)
cm[['hate']
]
cm['hate']
cm['hate1']
cm['hate1',]
cm['hate',]
nrow(merge('hate1',cm)) > 0
nrow(merge('hate2',cm)) > 0
nrow(merge('hate',cm)) > 0
cm
cm['love']
cm['love',]
cm['love1',]
dim(cm)
nrow(cm)
TRUE || FALSE
FALSE || TRUE
cm['love1']
cm['love']
cm['love',]
rm(list=ls())
source("data_retrieval.R")
source("preprocessing.R")
source("feature_construction.R")
source("training.R")
# retrive tweets and preprocess
tweets = retrieve.tweets(n=1000)
tweets$text <- sapply(tweets$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
vc_tweets = Corpus(VectorSource(as.character(tweets$text)))
vc_tweets = process.tweets(vc_tweets)
# create Document-Term Matrix
tweets.tdm <- DocumentTermMatrix(vc_tweets, control=list(minWordLength=1))
index <- sample(1:dim(tweets.tdm)[1])
tweets.tdm.training <- tweets.tdm[index[1:floor(dim(tweets.tdm)[1]/2)],]
tweets.tdm.test <- tweets.tdm[index[((ceiling(dim(tweets.tdm)[1]/2)) + 1):dim(tweets.tdm)[1]],]
# extract features from training data
tweets.tdm.df <- extract.features(tweets.tdm.training)
# assign 'Class' to tweets
tweets.tdm.df["Class"] <- "love"
tweets.tdm.df[tweets.tdm.df$hate > 0, "Class"] <- "hate"
# removes 'love' and 'hate' from the feature set
tweets.tdm.df <- tweets.tdm.df[setdiff(colnames(tweets.tdm.df), c("love", "hate"))]
# train model
tweetModel <- trainModel(tweets.tdm.df, training = T)
predictions <- predict(tweetModel, newdata = tweets.tdm.df, type = "response")
summary(predictions)
table(predictions,tweets.tdm.df[,ncol(tweets.tdm.df)])
test.matrix <- as.matrix(tweets.tdm.test)
tweets.tdm.test <- as.data.frame(test.matrix)
# add 'Class' to test data
tweets.tdm.test["Class"] <- "love"
tweets.tdm.test[tweets.tdm.test$hate > 0, "Class"] <- "hate"
tweets.tdm.test <- tweets.tdm.test[setdiff(colnames(tweets.tdm.test), c("love", "hate"))]
# predict using our model for test data
#prediction <- predict(tweetModel, newdata = tweets.tdm.test, type = "response")
#newModel <- trainModel(tweets.tdm.test, training = F, trainedModel = tweetModel)
chunk <- 50
for(i in seq(1, dim(tweets.tdm.test)[1], chunk)) {
tp <- 0
tn <- 0
fp <- 0
fn <- 0
dataset <- tweets.tdm.test[seq(i:i+chunk-1),]
prediction <- predict(tweetModel, newdata = dataset, type = "response")
tweetModel <- trainModel(dataset, training = F, trainedModel = tweetModel)
cm <- table(prediction,dataset[,ncol(dataset)])
if(nrow(cm) == 1) {
if(!is.na(cm['love'])) {
tp <- cm['love', 'love']
fp <- cm['love', 'hate']
}
else {
tn <- cm['hate', 'hate']
fn <- cm['hate', 'love']
}
}
else {
tp <- cm['love', 'love']
fp <- cm['love', 'hate']
tn <- cm['hate', 'hate']
fn <- cm['hate', 'love']
}
accuracy = (tp + tn) / (tp + tn + fp + fn)
print(paste('running iteration ', i, ' accuracy: ', accuracy))
}
cm
(423+26)/(500)
